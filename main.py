from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Dict, List, Optional
import threading
import schedule
import time
import uvicorn
import asyncio
from datetime import datetime, timedelta

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ìž„í¬íŠ¸
from config import DEFAULT_SYMBOL, TIMEFRAMES, SCHEDULER_INTERVAL_MINUTES, get_symbol_display_name, normalize_symbol, logger
from database import db
from market_analyzer import market_analyzer, initialize_historical_data
from ai_system import ai_system
from trading_engine import trading_engine, risk_manager, position_manager
from notion_integration import notion_config, notion_logger
from master_agent import master_agent
from virtual_portfolio import virtual_portfolio
from market_data import market_data_collector
from position_monitor import position_monitor


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Trading Bot API",
    description="AI ê¸°ë°˜ ë©€í‹° ì‹¬ë³¼ ì•”í˜¸í™”í íŠ¸ë ˆì´ë”© ë´‡ (ì‹œê·¸ë„ ê¸°ë°˜)",
    version="2.0.0",
    docs_url="/docs",  # ì´ ì¤„ì´ ìžˆëŠ”ì§€ í™•ì¸
    redoc_url="/redoc"  # ì´ ì¤„ë„ í™•ì¸
)

# ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ
collection_status = {
    "running": False,
    "started_at": None,
    "errors": []
}

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ
scheduler_status = {
    "running": False,
    "started_at": None,
    "mode": "signal_based",
    "signal_check_interval": 5,
    "verification_interval": 15,
    "analysis_count": 0,
    "verification_count": 0,
    "signal_detection_count": 0,
    "last_run": None,
    "last_signal_check": None,
    "errors": []
}


class AgentAnalysisRequest(BaseModel):
    agent_name: str
    analysis_periods: int = 50


class SignalBasedScheduler:
    """ê°œì„ ëœ ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ìŠ¤ì¼€ì¤„ëŸ¬ í´ëž˜ìŠ¤ - ì •ê° ê¸°ì¤€ ì‹¤í–‰"""
    
    def __init__(self):
        self.running = False
        self.thread = None
        self.analysis_count = 0
        self.verification_count = 0
        self.signal_detection_count = 0
        self.data_collection_count = 0
        self.last_run = None
        self.last_signal_check = None
        self.last_data_collection = None
        self.errors = []
        self.signal_detector = None
        
        # ì •ê° ê¸°ì¤€ ì‹¤í–‰ ì‹œê°„ ì„¤ì •
        self.data_collection_schedule = {
            '5m': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56],  # 5ë¶„ë§ˆë‹¤
            '15m': [1, 16, 31, 46],  # 15ë¶„ë§ˆë‹¤
            '1h': [1]  # ë§¤ì‹œ 1ë¶„
        }
        
        # ì‹œê·¸ë„ ì²´í¬ëŠ” ë°ì´í„° ìˆ˜ì§‘ 2ë¶„ í›„ (ì•ˆì „ ë§ˆì§„)
        self.signal_check_schedule = {
            '5m': [3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58],  # 5ë¶„ë§ˆë‹¤ + 2ë¶„
            '15m': [3, 18, 33, 48],  # 15ë¶„ë§ˆë‹¤ + 2ë¶„
            '1h': [3]  # ë§¤ì‹œ 3ë¶„
        }
        
        # ê²€ì¦ì€ 15ë¶„ë§ˆë‹¤
        self.verification_schedule = [3, 18, 33, 48]
    
    def start_scheduler(self):
        """ì‹œê°„ ë™ê¸°í™”ëœ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘"""
        if self.running:
            logger.warning("ì‹œê·¸ë„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤")
            return False
        
        if not ai_system.is_available():
            logger.error("AI ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œìž‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        if not notion_logger.is_available():
            logger.error("ë…¸ì…˜ ì—°ë™ì´ ë¶ˆê°€ëŠ¥í•˜ì—¬ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œìž‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # SignalDetector ì´ˆê¸°í™”
        try:
            from market_analyzer import SignalDetector
            self.signal_detector = SignalDetector()
            logger.info("ì‹œê·¸ë„ ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì‹œê·¸ë„ ê°ì§€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
        
        # ì •ê° ê¸°ì¤€ ìŠ¤ì¼€ì¤„ ë“±ë¡
        self._register_synchronized_schedules()
        
        self.running = True
        self.thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.thread.start()
        
        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        global scheduler_status
        scheduler_status.update({
            "running": True,
            "started_at": datetime.now().isoformat(),
            "mode": "synchronized_signal_based",
            "data_collection_schedule": self.data_collection_schedule,
            "signal_check_schedule": self.signal_check_schedule,
            "verification_schedule": self.verification_schedule,
            "errors": []
        })
        
        logger.info(f"ðŸ•’ === ì‹œê°„ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘ ===")
        logger.info(f"ðŸ“Š ë°ì´í„° ìˆ˜ì§‘: 5ë¶„({len(self.data_collection_schedule['5m'])}íšŒ/ì‹œ), 15ë¶„({len(self.data_collection_schedule['15m'])}íšŒ/ì‹œ), 1ì‹œê°„({len(self.data_collection_schedule['1h'])}íšŒ/ì‹œ)")
        logger.info(f"ðŸš¨ ì‹œê·¸ë„ ì²´í¬: 5ë¶„({len(self.signal_check_schedule['5m'])}íšŒ/ì‹œ), 15ë¶„({len(self.signal_check_schedule['15m'])}íšŒ/ì‹œ), 1ì‹œê°„({len(self.signal_check_schedule['1h'])}íšŒ/ì‹œ)")
        logger.info(f"ðŸ” ê²€ì¦: {len(self.verification_schedule)}íšŒ/ì‹œ")
        
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ í‘œì‹œ
        self._log_next_execution_times()
        
        return True
    
    def _register_synchronized_schedules(self):
        """ì •ê° ê¸°ì¤€ ë™ê¸°í™”ëœ ìŠ¤ì¼€ì¤„ ë“±ë¡"""
        logger.info("ì •ê° ê¸°ì¤€ ìŠ¤ì¼€ì¤„ ë“±ë¡ ì¤‘...")
        
        # ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„
        for timeframe, minutes in self.data_collection_schedule.items():
            for minute in minutes:
                schedule.every().hour.at(f":{minute:02d}").do(
                    self._data_collection_job, timeframe
                ).tag(f"data_{timeframe}")
        
        # ì‹œê·¸ë„ ì²´í¬ ìŠ¤ì¼€ì¤„ (í†µí•©)
        for minute in self.signal_check_schedule['5m']:  # ê°€ìž¥ ë¹ˆë²ˆí•œ 5ë¶„ ìŠ¤ì¼€ì¤„ ì‚¬ìš©
            schedule.every().hour.at(f":{minute:02d}").do(
                self._signal_detection_job
            ).tag("signal_check")
        
        # ê²€ì¦ ìŠ¤ì¼€ì¤„
        for minute in self.verification_schedule:
            schedule.every().hour.at(f":{minute:02d}").do(
                self._verification_job
            ).tag("verification")
        
        logger.info(f"ì´ {len(schedule.get_jobs())}ê°œ ì •ê° ê¸°ì¤€ ìž‘ì—… ë“±ë¡ ì™„ë£Œ")
    
    def stop_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.running = False
        schedule.clear()
        
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=5)
        
        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        global scheduler_status
        scheduler_status.update({
            "running": False,
            "started_at": None,
            "mode": "stopped"
        })
        
        logger.info("ì‹œê°„ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€")
    
    def _run_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„"""
        logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„ ì‹œìž‘ - ë‹¤ìŒ ì •ê° ì‹¤í–‰ ëŒ€ê¸° ì¤‘...")
        
        while self.running:
            try:
                schedule.run_pending()
                time.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì²´í¬ (ë” ì •í™•í•œ íƒ€ì´ë°)
            except Exception as e:
                logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                self.errors.append(f"{datetime.now()}: {str(e)}")
                scheduler_status["errors"] = self.errors[-5:]  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
                time.sleep(60)
    
    def _data_collection_job(self, timeframe: str):
        """ë°ì´í„° ìˆ˜ì§‘ ìž‘ì—… (ì •ê° ê¸°ì¤€)"""
        current_time = datetime.now()
        logger.info(f"ðŸ“Š === {current_time.strftime('%H:%M')} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘ ===")
        
        try:
            self.last_data_collection = current_time
            scheduler_status["last_data_collection"] = self.last_data_collection.isoformat()
            
            # í™œì„±í™”ëœ ì‹¬ë³¼ë“¤ ì¡°íšŒ
            if not notion_config.is_available():
                logger.error("ë…¸ì…˜ ì„¤ì • ê´€ë¦¬ìžë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            active_symbols = notion_config.get_all_symbols()
            if not active_symbols:
                logger.warning("í™œì„±í™”ëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return
            
            logger.info(f"ë°ì´í„° ìˆ˜ì§‘ ëŒ€ìƒ ì‹¬ë³¼ {len(active_symbols)}ê°œ: {active_symbols}")
            
            # ê° ì‹¬ë³¼ë³„ë¡œ í•´ë‹¹ ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘
            success_count = 0
            total_symbols = len(active_symbols)
            
            for symbol in active_symbols:
                try:
                    # ìµœì‹  ë°ì´í„° í™•ë³´ (ë§ˆì§€ë§‰ 2ì‹œê°„ ë¶„ëŸ‰)
                    success = market_analyzer.ensure_recent_data(symbol, hours_back=2)
                    if success:
                        success_count += 1
                        logger.debug(f"âœ… {symbol} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
                    else:
                        logger.warning(f"âŒ {symbol} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    
                    time.sleep(0.5)  # ì‹¬ë³¼ ê°„ ê°„ê²©
                    
                except Exception as e:
                    logger.error(f"âŒ {symbol} {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            
            self.data_collection_count += 1
            scheduler_status["data_collection_count"] = self.data_collection_count
            
            logger.info(f"âœ… === {timeframe} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{total_symbols} ì„±ê³µ ===")
            
        except Exception as e:
            logger.error(f"{timeframe} ë°ì´í„° ìˆ˜ì§‘ ìž‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.errors.append(f"{datetime.now()}: {str(e)}")
            scheduler_status["errors"] = self.errors[-5:]
    
    def _signal_detection_job(self):
        """ì‹œê·¸ë„ ê°ì§€ ìž‘ì—… (ì •ê° ê¸°ì¤€)"""
        current_time = datetime.now()
        logger.info(f"ðŸ” === {current_time.strftime('%H:%M')} ì‹œê·¸ë„ ê°ì§€ ì‹œìž‘ ===")
        
        try:
            self.last_signal_check = current_time
            scheduler_status["last_signal_check"] = self.last_signal_check.isoformat()
            
            # í™œì„±í™”ëœ ì‹¬ë³¼ë“¤ ì¡°íšŒ
            if not notion_config.is_available():
                logger.error("ë…¸ì…˜ ì„¤ì • ê´€ë¦¬ìžë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return
            
            active_symbols = notion_config.get_all_symbols()
            if not active_symbols:
                logger.warning("í™œì„±í™”ëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return
            
            logger.info(f"ì‹œê·¸ë„ ê°ì§€ ëŒ€ìƒ ì‹¬ë³¼ {len(active_symbols)}ê°œ: {active_symbols}")
            
            # ëª¨ë“  ì‹¬ë³¼ì˜ ì‹œê·¸ë„ ê°ì§€
            all_signals = self.signal_detector.detect_signals_for_all_symbols(active_symbols)
            
            self.signal_detection_count += 1
            scheduler_status["signal_detection_count"] = self.signal_detection_count
            
            if not all_signals:
                logger.info("ê°ì§€ëœ ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤")
                return
            
            # ì‹œê·¸ë„ ìš”ì•½
            signal_summary = self.signal_detector.get_signal_summary(all_signals)
            logger.info(f"ðŸ“Š ì‹œê·¸ë„ ê°ì§€ ìš”ì•½: {signal_summary['total_signals']}ê°œ ì‹œê·¸ë„, "
                       f"{signal_summary['symbols_with_signals']}ê°œ ì‹¬ë³¼, "
                       f"ê³ ìš°ì„ ìˆœìœ„: {signal_summary['high_priority_signals']}ê°œ")
            
            # ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰
            analysis_results = self._execute_signal_based_analyses(all_signals)
            
            # ì¹´ìš´í„° ì—…ë°ì´íŠ¸
            self.analysis_count += analysis_results['success_count']
            scheduler_status["analysis_count"] = self.analysis_count
            
            logger.info(f"âœ… === ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ: {analysis_results['success_count']}ê°œ ì„±ê³µ, {analysis_results['failure_count']}ê°œ ì‹¤íŒ¨ ===")
            
        except Exception as e:
            logger.error(f"ì‹œê·¸ë„ ê°ì§€ ìž‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.errors.append(f"{datetime.now()}: {str(e)}")
            scheduler_status["errors"] = self.errors[-5:]
    
    def _verification_job(self):
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ìž‘ì—… (ì •ê° ê¸°ì¤€)"""
        current_time = datetime.now()
        logger.info(f"ðŸ” === {current_time.strftime('%H:%M')} ê²€ì¦ ì‹œìž‘ ===")
        
        try:
            verification_results = self._verify_previous_analyses()
            
            self.verification_count += verification_results['verified_count']
            scheduler_status["verification_count"] = self.verification_count
            
            logger.info(f"âœ… === ê²€ì¦ ì™„ë£Œ: {verification_results['verified_count']}ê°œ "
                       f"(ì„±ê³µ: {verification_results['success_count']}, ì‹¤íŒ¨: {verification_results['failure_count']}) ===")
            
        except Exception as e:
            logger.error(f"ê²€ì¦ ìž‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.errors.append(f"{datetime.now()}: {str(e)}")
            scheduler_status["errors"] = self.errors[-5:]
    
    def _log_next_execution_times(self):
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë“¤ ë¡œê¹…"""
        try:
            current_time = datetime.now()
            
            # ë‹¤ìŒ ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„
            next_data_5m = self._get_next_execution_time(self.data_collection_schedule['5m'])
            next_data_15m = self._get_next_execution_time(self.data_collection_schedule['15m'])
            next_data_1h = self._get_next_execution_time(self.data_collection_schedule['1h'])
            
            # ë‹¤ìŒ ì‹œê·¸ë„ ì²´í¬ ì‹œê°„
            next_signal = self._get_next_execution_time(self.signal_check_schedule['5m'])
            
            # ë‹¤ìŒ ê²€ì¦ ì‹œê°„
            next_verification = self._get_next_execution_time(self.verification_schedule)
            
            logger.info(f"â° ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„:")
            logger.info(f"  ðŸ“Š 5ë¶„ ë°ì´í„°: {next_data_5m.strftime('%H:%M')}")
            logger.info(f"  ðŸ“Š 15ë¶„ ë°ì´í„°: {next_data_15m.strftime('%H:%M')}")
            logger.info(f"  ðŸ“Š 1ì‹œê°„ ë°ì´í„°: {next_data_1h.strftime('%H:%M')}")
            logger.info(f"  ðŸš¨ ì‹œê·¸ë„ ì²´í¬: {next_signal.strftime('%H:%M')}")
            logger.info(f"  ðŸ” ê²€ì¦: {next_verification.strftime('%H:%M')}")
            
        except Exception as e:
            logger.warning(f"ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    def _get_next_execution_time(self, minute_list: List[int]) -> datetime:
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°"""
        current_time = datetime.now()
        current_minute = current_time.minute
        
        # í˜„ìž¬ ì‹œê°„ ì´í›„ì˜ ë‹¤ìŒ ì‹¤í–‰ ë¶„ ì°¾ê¸°
        next_minute = None
        for minute in sorted(minute_list):
            if minute > current_minute:
                next_minute = minute
                break
        
        if next_minute is None:
            # ë‹¤ìŒ ì‹œê°„ì˜ ì²« ë²ˆì§¸ ì‹¤í–‰ ë¶„
            next_minute = min(minute_list)
            next_time = current_time.replace(minute=next_minute, second=0, microsecond=0) + timedelta(hours=1)
        else:
            next_time = current_time.replace(minute=next_minute, second=0, microsecond=0)
        
        return next_time
    
    def wait_for_next_sync_point(self):
        """ë‹¤ìŒ ë™ê¸°í™” ì§€ì ê¹Œì§€ ëŒ€ê¸°"""
        current_time = datetime.now()
        
        # ëª¨ë“  ì‹¤í–‰ ì‹œê°„ ì¤‘ ê°€ìž¥ ê°€ê¹Œìš´ ì‹œê°„ ì°¾ê¸°
        all_minutes = set()
        all_minutes.update(self.data_collection_schedule['5m'])
        all_minutes.update(self.signal_check_schedule['5m'])
        all_minutes.update(self.verification_schedule)
        
        next_exec_time = self._get_next_execution_time(list(all_minutes))
        wait_seconds = (next_exec_time - current_time).total_seconds()
        
        if wait_seconds > 0:
            logger.info(f"â³ ë‹¤ìŒ ë™ê¸°í™” ì§€ì ê¹Œì§€ ëŒ€ê¸°: {next_exec_time.strftime('%H:%M')} ({wait_seconds:.0f}ì´ˆ)")
            time.sleep(min(wait_seconds, 300))  # ìµœëŒ€ 5ë¶„ë§Œ ëŒ€ê¸°
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì½”ë“œê°€ ë„ˆë¬´ ê¸¸ì–´ì ¸ì„œ ìƒëžµ)
    def _execute_signal_based_analyses(self, all_signals: Dict[str, List[Dict]]) -> Dict:
        """ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰ - ê°œë³„ ë¶„ì„ í›„ ì´ê´„ ì—ì´ì „íŠ¸ í˜¸ì¶œ"""
        analysis_results = {
            "success_count": 0,
            "failure_count": 0,
            "total_symbols": 0,
            "master_decisions": 0,
            "trading_executions": 0,
            "details": []
        }
        
        try:
            # ì‹¬ë³¼ë³„ë¡œ ê·¸ë£¹í™” (ì´ë¯¸ ì‹¬ë³¼ë³„ë¡œ ë˜ì–´ ìžˆìŒ)
            analysis_results["total_symbols"] = len(all_signals)
            
            # ê° ì‹¬ë³¼ì— ëŒ€í•´ í•œ ë²ˆì”©ë§Œ ë¶„ì„ ì‹¤í–‰
            for symbol, signals in all_signals.items():
                try:
                    logger.info(f"ðŸš¨ {symbol} ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ì‹œìž‘ - {len(signals)}ê°œ ì‹œê·¸ë„ ê°ì§€")
                    
                    # í•´ë‹¹ ì‹¬ë³¼ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸ë“¤ ì¡°íšŒ
                    agents_for_symbol = notion_config.get_agents_by_symbol(symbol)
                    
                    if not agents_for_symbol:
                        logger.warning(f"{symbol}ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                        analysis_results["failure_count"] += 1
                        
                        analysis_results["details"].append({
                            "symbol": symbol,
                            "signals": [s['type'] for s in signals],
                            "signal_count": len(signals),
                            "success": False,
                            "error": "í•´ë‹¹ ì‹¬ë³¼ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸ ì—†ìŒ"
                        })
                        continue
                    
                    # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œ ë¶„ì„ (í–¥í›„ ì—ì´ì „íŠ¸ ì„ íƒ ë¡œì§ ê°œì„  ê°€ëŠ¥)
                    agent_info = agents_for_symbol[0]
                    agent_name = agent_info['name']
                    
                    # ì‹œê·¸ë„ ì •ë³´ ìš”ì•½ (ë¶„ì„ì— í¬í•¨í•  ì»¨í…ìŠ¤íŠ¸)
                    signal_context = self._create_signal_context(signals)
                    
                    logger.info(f"ðŸ¤– {agent_name} ì—ì´ì „íŠ¸ë¡œ {symbol} ë¶„ì„ ì‹œìž‘...")
                    logger.info(f"ðŸ“Š ê°ì§€ëœ ì‹œê·¸ë„: {[s['type'] for s in signals]}")
                    
                    # AI ë¶„ì„ ìˆ˜í–‰
                    analysis_result = ai_system.analyze_with_agent(agent_name, analysis_periods=50)
                    
                    if analysis_result and not analysis_result.get("error"):
                        # í˜„ìž¬ê°€ ì¡°íšŒ
                        current_price_data = db.get_current_price(symbol)
                        current_price = current_price_data['price'] if current_price_data else 0
                        
                        # ë¶„ì„ ê²°ê³¼ì— ëª¨ë“  ì‹œê·¸ë„ ì •ë³´ ì¶”ê°€
                        analysis_result['triggered_signals'] = {
                            'count': len(signals),
                            'signals': signals,
                            'summary': signal_context,
                            'strongest_signal': max(signals, key=lambda x: self._get_signal_priority_score(x))
                        }
                        
                        # ë…¸ì…˜ì— ê°œë³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥
                        individual_page_id = notion_logger.create_analysis_page(analysis_result, current_price)
                        
                        if individual_page_id:
                            analysis_results["success_count"] += 1
                            logger.info(f"âœ… {agent_name} ({symbol}): {analysis_result['recommendation']} "
                                    f"(ì‹ ë¢°ë„: {analysis_result['confidence']:.1%}) - "
                                    f"ì‹œê·¸ë„ {len(signals)}ê°œ ê¸°ë°˜")
                            
                            # ðŸ”¥ ì—¬ê¸°ê°€ í•µì‹¬: ì´ê´„ ì—ì´ì „íŠ¸ í˜¸ì¶œ
                            logger.info(f"ðŸŽ¯ ì´ê´„ ì—ì´ì „íŠ¸ í˜¸ì¶œ: {symbol}")
                            
                            if master_agent.is_available():
                                master_decision = master_agent.make_trading_decision(
                                    analysis_result, 
                                    analysis_result['triggered_signals']
                                )
                                
                                if master_decision:
                                    analysis_results["master_decisions"] += 1
                                    
                                    # ì´ê´„ ê²°ì • ë…¸ì…˜ íŽ˜ì´ì§€ ìƒì„±
                                    trading_page_id = notion_logger.create_trading_decision_page(
                                        master_decision, 
                                        analysis_result
                                    )
                                    
                                    # ì‹¤ì œ ë§¤ë§¤ê°€ ì‹¤í–‰ëœ ê²½ìš° ì¹´ìš´íŠ¸
                                    execution_result = master_decision.get('execution_result', {})
                                    if execution_result.get('success') and execution_result.get('action') in ['ENTER', 'EXIT']:
                                        analysis_results["trading_executions"] += 1
                                    
                                    logger.info(f"ðŸ† ì´ê´„ ê²°ì • ì™„ë£Œ: {symbol} -> {master_decision.get('trading_decision', 'UNKNOWN')}")
                                    
                                    analysis_results["details"].append({
                                        "agent_name": agent_name,
                                        "symbol": symbol,
                                        "signals": [s['type'] for s in signals],
                                        "signal_count": len(signals),
                                        "strongest_signal": signals[0]['type'] if signals else None,
                                        "success": True,
                                        "recommendation": analysis_result.get('recommendation'),
                                        "confidence": analysis_result.get('confidence'),
                                        "individual_page_id": individual_page_id,
                                        "master_decision": master_decision.get('trading_decision'),
                                        "master_confidence": master_decision.get('confidence'),
                                        "trading_page_id": trading_page_id,
                                        "execution_success": execution_result.get('success', False),
                                        "execution_action": execution_result.get('action', 'NONE')
                                    })
                                else:
                                    logger.error(f"âŒ ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ì‹¤íŒ¨: {symbol}")
                                    analysis_results["details"].append({
                                        "agent_name": agent_name,
                                        "symbol": symbol,
                                        "signals": [s['type'] for s in signals],
                                        "signal_count": len(signals),
                                        "success": True,
                                        "individual_page_id": individual_page_id,
                                        "master_decision_error": "ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ì‹¤íŒ¨"
                                    })
                            else:
                                logger.warning(f"âš ï¸ ì´ê´„ ì—ì´ì „íŠ¸ ì‚¬ìš© ë¶ˆê°€: {symbol}")
                                analysis_results["details"].append({
                                    "agent_name": agent_name,
                                    "symbol": symbol,
                                    "signals": [s['type'] for s in signals],
                                    "signal_count": len(signals),
                                    "success": True,
                                    "individual_page_id": individual_page_id,
                                    "master_decision_error": "ì´ê´„ ì—ì´ì „íŠ¸ ì‚¬ìš© ë¶ˆê°€"
                                })
                        else:
                            analysis_results["failure_count"] += 1
                            logger.error(f"âŒ {agent_name} ({symbol}): ë¶„ì„ ì™„ë£Œí–ˆìœ¼ë‚˜ ë…¸ì…˜ ì €ìž¥ ì‹¤íŒ¨")
                            
                            analysis_results["details"].append({
                                "agent_name": agent_name,
                                "symbol": symbol,
                                "signals": [s['type'] for s in signals],
                                "signal_count": len(signals),
                                "success": False,
                                "error": "ë…¸ì…˜ ê°œë³„ ë¶„ì„ íŽ˜ì´ì§€ ì €ìž¥ ì‹¤íŒ¨"
                            })
                    else:
                        analysis_results["failure_count"] += 1
                        error_msg = analysis_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") if analysis_result else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
                        logger.error(f"âŒ {agent_name} ({symbol}): ë¶„ì„ ì‹¤íŒ¨ - {error_msg}")
                        
                        analysis_results["details"].append({
                            "agent_name": agent_name,
                            "symbol": symbol,
                            "signals": [s['type'] for s in signals],
                            "signal_count": len(signals),
                            "success": False,
                            "error": error_msg
                        })
                    
                    # ì‹¬ë³¼ ê°„ ê°„ê²© (API ì œí•œ ê³ ë ¤)
                    time.sleep(3)
                    
                except Exception as e:
                    analysis_results["failure_count"] += 1
                    logger.error(f"âŒ {symbol} ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                    analysis_results["details"].append({
                        "symbol": symbol,
                        "signals": [s['type'] for s in signals] if signals else [],
                        "signal_count": len(signals) if signals else 0,
                        "success": False,
                        "error": str(e)
                    })
            
            # ìµœì¢… ìš”ì•½ ë¡œê·¸
            logger.info(f"ðŸŽ¯ === ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ìµœì¢… ì™„ë£Œ ===")
            logger.info(f"ðŸ“Š ê°œë³„ ë¶„ì„: {analysis_results['success_count']}ê°œ ì„±ê³µ, {analysis_results['failure_count']}ê°œ ì‹¤íŒ¨")
            logger.info(f"ðŸ¤– ì´ê´„ ê²°ì •: {analysis_results['master_decisions']}ê°œ ì™„ë£Œ")
            logger.info(f"âš™ï¸ ë§¤ë§¤ ì‹¤í–‰: {analysis_results['trading_executions']}ê°œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì‹œê·¸ë„ ê¸°ë°˜ ë¶„ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜: {e}")
        
        return analysis_results
    
    def _create_signal_context(self, signals: List[Dict]) -> str:
        """ì‹œê·¸ë„ë“¤ì„ ë¶„ì„ìš© ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not signals:
            return "ì‹œê·¸ë„ ì—†ìŒ"
        
        # ì‹œê·¸ë„ì„ ê°•ë„ë³„ë¡œ ë¶„ë¥˜
        very_high = [s for s in signals if s.get('strength') == 'VERY_HIGH']
        high = [s for s in signals if s.get('strength') == 'HIGH']
        medium = [s for s in signals if s.get('strength') == 'MEDIUM']
        
        context_parts = []
        
        if very_high:
            context_parts.append(f"ë§¤ìš° ê°•í•œ ì‹œê·¸ë„: {[s['type'] for s in very_high]}")
        if high:
            context_parts.append(f"ê°•í•œ ì‹œê·¸ë„: {[s['type'] for s in high]}")
        if medium:
            context_parts.append(f"ì¤‘ê°„ ì‹œê·¸ë„: {[s['type'] for s in medium]}")
        
        # ë°©í–¥ì„± ë¶„ì„
        buy_signals = [s for s in signals if s.get('direction') == 'BUY']
        sell_signals = [s for s in signals if s.get('direction') == 'SELL']
        
        if len(buy_signals) > len(sell_signals):
            direction_bias = f"ê°•ì„¸ íŽ¸í–¥ ({len(buy_signals)}ê°œ vs {len(sell_signals)}ê°œ)"
        elif len(sell_signals) > len(buy_signals):
            direction_bias = f"ì•½ì„¸ íŽ¸í–¥ ({len(sell_signals)}ê°œ vs {len(buy_signals)}ê°œ)"
        else:
            direction_bias = "ì¤‘ë¦½ì "
        
        context_parts.append(f"ë°©í–¥ì„±: {direction_bias}")
        
        return " | ".join(context_parts)

    def _get_signal_priority_score(self, signal: Dict) -> int:
        """ì‹œê·¸ë„ ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°"""
        strength_scores = {
            'VERY_HIGH': 4,
            'HIGH': 3,
            'MEDIUM': 2,
            'LOW': 1
        }
        
        strength_score = strength_scores.get(signal.get('strength', 'LOW'), 1)
        priority_score = signal.get('priority', 1)
        
        return strength_score * priority_score
    
    def _verify_previous_analyses(self) -> Dict:
        """ì´ì „ ë¶„ì„ ê²°ê³¼ ê²€ì¦"""
        logger.info(f"ðŸ” 15ë¶„ ì „ ë¶„ì„ ê²°ê³¼ ê²€ì¦ ì‹œìž‘...")
        
        verification_results = {
            "verified_count": 0,
            "success_count": 0,
            "failure_count": 0,
            "details": []
        }
        
        try:
            # ë…¸ì…˜ì—ì„œ ê²€ì¦ ëŒ€ê¸° ì¤‘ì¸ ë¶„ì„ë“¤ ì¡°íšŒ
            pending_analyses = notion_logger.get_pending_verifications(minutes_ago=15)
            
            if not pending_analyses:
                logger.info("ê²€ì¦í•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                return verification_results
            
            logger.info(f"ê²€ì¦ ëŒ€ê¸° ì¤‘ì¸ ë¶„ì„ {len(pending_analyses)}ê°œ ë°œê²¬")
            
            # ê° ë¶„ì„ ê²€ì¦
            for analysis in pending_analyses:
                try:
                    # í•´ë‹¹ ë¶„ì„ì˜ ì‹¬ë³¼ í™•ì¸
                    analysis_symbol = analysis.get('symbol', 'SOL/USDT')
                    
                    # í•´ë‹¹ ì‹¬ë³¼ì˜ í˜„ìž¬ê°€ ì¡°íšŒ
                    current_price_data = db.get_current_price(analysis_symbol)
                    if not current_price_data:
                        logger.error(f"{analysis_symbol} í˜„ìž¬ê°€ ì¡°íšŒ ì‹¤íŒ¨ - ê²€ì¦ ë¶ˆê°€")
                        continue
                    
                    current_price = current_price_data['price']
                    logger.info(f"{analysis_symbol} í˜„ìž¬ ê°€ê²©: ${current_price:.4f}")
                    
                    result = self._verify_single_analysis(analysis, current_price)
                    verification_results["details"].append(result)
                    verification_results["verified_count"] += 1
                    
                    if result["verification_result"] == "ì„±ê³µ":
                        verification_results["success_count"] += 1
                    else:
                        verification_results["failure_count"] += 1
                        
                except Exception as e:
                    logger.error(f"ê°œë³„ ë¶„ì„ ê²€ì¦ ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²€ì¦ ê³¼ì •ì—ì„œ ì˜¤ë¥˜: {e}")
        
        return verification_results
    
    def _verify_single_analysis(self, analysis: Dict, current_price: float) -> Dict:
        """ê°œë³„ ë¶„ì„ ê²°ê³¼ ê²€ì¦"""
        page_id = analysis['page_id']
        recommendation = analysis['recommendation']
        original_price = analysis['original_price']
        target_price = analysis['target_price']
        stop_loss = analysis['stop_loss']
        
        # ê²€ì¦ ë¡œì§
        verification_result = self._determine_verification_result(
            recommendation, original_price, current_price, target_price, stop_loss
        )
        
        # ë…¸ì…˜ ì—…ë°ì´íŠ¸
        success = notion_logger.update_verification_result(
            page_id, verification_result, current_price, original_price
        )
        
        result_detail = {
            "page_id": page_id,
            "recommendation": recommendation,
            "original_price": original_price,
            "current_price": current_price,
            "target_price": target_price,
            "stop_loss": stop_loss,
            "verification_result": verification_result,
            "update_success": success
        }
        
        if success:
            price_change_pct = ((current_price - original_price) / original_price) * 100
            logger.info(f"âœ… ê²€ì¦ ì™„ë£Œ: {recommendation} â†’ {verification_result} "
                       f"(${original_price:.4f} â†’ ${current_price:.4f}, {price_change_pct:+.2f}%)")
        else:
            logger.error(f"âŒ ê²€ì¦ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {page_id}")
        
        return result_detail
    
    def _determine_verification_result(self, recommendation: str, original_price: float, 
                                     current_price: float, target_price: float, stop_loss: float) -> str:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë¡œì§"""
        try:
            if recommendation == "BUY":
                if current_price >= target_price:
                    return "ì„±ê³µ"
                elif current_price <= stop_loss:
                    return "ì‹¤íŒ¨"
                else:
                    return "ì„±ê³µ" if current_price > original_price else "ì‹¤íŒ¨"
                    
            elif recommendation == "SELL":
                if current_price <= target_price:
                    return "ì„±ê³µ"
                elif current_price >= stop_loss:
                    return "ì‹¤íŒ¨"
                else:
                    return "ì„±ê³µ" if current_price < original_price else "ì‹¤íŒ¨"
                    
            elif recommendation == "HOLD":
                price_change_pct = abs((current_price - original_price) / original_price) * 100
                return "ì„±ê³µ" if price_change_pct <= 2.0 else "ì‹¤íŒ¨"
                
            else:
                return "ì‹¤íŒ¨"
                
        except Exception as e:
            logger.error(f"ê²€ì¦ ê²°ê³¼ íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì‹¤íŒ¨"
    
    def run_immediate_signal_detection(self) -> Optional[str]:
        """ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ ì‹¤í–‰ (ìˆ˜ë™ íŠ¸ë¦¬ê±°ìš©)"""
        try:
            logger.info("ðŸš€ ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ ì‹¤í–‰")
            
            if not self.signal_detector:
                from market_analyzer import SignalDetector
                self.signal_detector = SignalDetector()
            
            active_symbols = notion_config.get_all_symbols()
            all_signals = self.signal_detector.detect_signals_for_all_symbols(active_symbols)
            
            if all_signals:
                analysis_results = self._execute_signal_based_analyses(all_signals)
                return f"ì‹œê·¸ë„ ê°ì§€ ë° ë¶„ì„ ì™„ë£Œ: {analysis_results['success_count']}ê°œ ì„±ê³µ, {analysis_results['failure_count']}ê°œ ì‹¤íŒ¨"
            else:
                return "ê°ì§€ëœ ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤"
                
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ ì‹¤íŒ¨: {e}")
            return None
    
    def run_immediate_verification(self) -> Optional[str]:
        """ì¦‰ì‹œ ê²€ì¦ ì‹¤í–‰ (ìˆ˜ë™ íŠ¸ë¦¬ê±°ìš©)"""
        try:
            logger.info("ðŸ” ì¦‰ì‹œ ê²€ì¦ ì‹¤í–‰")
            verification_results = self._verify_previous_analyses()
            return f"ê²€ì¦ ì™„ë£Œ: {verification_results['verified_count']}ê°œ (ì„±ê³µ: {verification_results['success_count']}, ì‹¤íŒ¨: {verification_results['failure_count']})"
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return None
    
    def get_scheduler_status(self) -> Dict:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
        next_data_times = {}
        next_signal_time = None
        next_verification_time = None
        
        if self.running:
            try:
                # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë“¤ ê³„ì‚°
                next_data_times = {
                    '5m': self._get_next_execution_time(self.data_collection_schedule['5m']).isoformat(),
                    '15m': self._get_next_execution_time(self.data_collection_schedule['15m']).isoformat(),
                    '1h': self._get_next_execution_time(self.data_collection_schedule['1h']).isoformat()
                }
                next_signal_time = self._get_next_execution_time(self.signal_check_schedule['5m']).isoformat()
                next_verification_time = self._get_next_execution_time(self.verification_schedule).isoformat()
            except:
                pass
        
        return {
            "running": self.running,
            "mode": "synchronized_signal_based",
            "data_collection_schedule": self.data_collection_schedule,
            "signal_check_schedule": self.signal_check_schedule,
            "verification_schedule": self.verification_schedule,
            "ai_available": ai_system.is_available(),
            "notion_available": notion_logger.is_available(),
            "agent_management_available": notion_config.is_available(),
            "active_agents": notion_config.get_agent_names() if notion_config.is_available() else [],
            "total_analyses": self.analysis_count,
            "total_verifications": self.verification_count,
            "total_signal_detections": self.signal_detection_count,
            "total_data_collections": self.data_collection_count,
            "last_signal_check": self.last_signal_check.isoformat() if self.last_signal_check else None,
            "last_data_collection": self.last_data_collection.isoformat() if self.last_data_collection else None,
            "next_data_collection_times": next_data_times,
            "next_signal_check": next_signal_time,
            "next_verification": next_verification_time,
            "recent_errors": self.errors[-5:] if self.errors else [],
            "current_time": datetime.now().isoformat()
        }


# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
signal_based_scheduler = SignalBasedScheduler()

scheduler_status = {
    "running": False,
    "started_at": None,
    "mode": "synchronized_signal_based",
    "data_collection_schedule": {},
    "signal_check_schedule": {},
    "verification_schedule": [],
    "analysis_count": 0,
    "verification_count": 0,
    "signal_detection_count": 0,
    "data_collection_count": 0,
    "last_run": None,
    "last_signal_check": None,
    "last_data_collection": None,
    "errors": []
}

def start_data_collection():
    """ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘"""
    global collection_status
    
    if collection_status["running"]:
        logger.warning("ë°ì´í„° ìˆ˜ì§‘ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤")
        return
    
    try:
        market_analyzer.start_data_collection()
        collection_status["running"] = True
        collection_status["started_at"] = datetime.now().isoformat()
        collection_status["errors"] = []
        logger.info("ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
    except Exception as e:
        logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘ ì‹¤íŒ¨: {e}")
        collection_status["errors"].append(str(e))


def stop_data_collection():
    """ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€"""
    global collection_status
    
    try:
        market_analyzer.stop_data_collection()
        collection_status["running"] = False
        logger.info("ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€")
    except Exception as e:
        logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€ ì‹¤íŒ¨: {e}")


@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œìž‘ ì‹œ ì´ˆê¸°í™” - ì‹œê°„ ë™ê¸°í™” í¬í•¨"""
    logger.info("Trading Bot API v2.1 ì‹œìž‘ (ì‹œê°„ ë™ê¸°í™” + ì‹œê·¸ë„ ê¸°ë°˜ + ì´ê´„ ì—ì´ì „íŠ¸)")
    
    try:
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ê°€ìƒ ê±°ëž˜ í…Œì´ë¸” í¬í•¨)
        db.init_database()
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 2. ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ í™•ì¸
        portfolio_status = virtual_portfolio.get_portfolio_status()
        logger.info(f"ðŸ’¼ ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ: ìž”ê³  ${portfolio_status['current_balance']:.2f}, "
                   f"ì´ìžì‚° ${portfolio_status['total_value']:.2f}, "
                   f"ìˆ˜ìµë¥  {portfolio_status['total_return']:+.2f}%")
        
        # 3. ì´ê´„ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        if master_agent.is_available():
            logger.info("ðŸ¤– ì´ê´„ ì—ì´ì „íŠ¸ ì‚¬ìš© ê°€ëŠ¥")
        else:
            logger.warning("âš ï¸ ì´ê´„ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 4. ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸
        try:
            fear_greed = market_data_collector.get_fear_greed_index()
            logger.info(f"ðŸ“Š ê³µí¬íƒìš•ì§€ìˆ˜: {fear_greed['value']} ({fear_greed['value_classification']})")
        except Exception as e:
            logger.warning(f"ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        # 5. ë…¸ì…˜ ì—ì´ì „íŠ¸ ì„¤ì • ë¡œë“œ
        if notion_config.is_available():
            success = notion_config.load_all_agents()
            if success:
                agents = notion_config.get_agent_names()
                symbols = notion_config.get_all_symbols()
                logger.info(f"ðŸŽ¯ íŠ¸ë ˆì´ë”© ì—ì´ì „íŠ¸ ë¡œë“œ ì™„ë£Œ: {agents}")
                logger.info(f"ðŸ“ˆ ë¶„ì„ ëŒ€ìƒ ì‹¬ë³¼: {symbols}")
                
                # ë°ì´í„° ìˆ˜ì§‘ê¸°ì— ì—ì´ì „íŠ¸ ì‹¬ë³¼ë“¤ ì—…ë°ì´íŠ¸
                market_analyzer.update_active_symbols(symbols)
            else:
                logger.warning("âŒ íŠ¸ë ˆì´ë”© ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨")
        else:
            logger.warning("âš ï¸ ë…¸ì…˜ ì„¤ì • ê´€ë¦¬ìžë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 6. ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘ (ê°œì„ ëœ ë²„ì „)
        start_data_collection()
        logger.info("ðŸ“¡ ê°œì„ ëœ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
        
        # 7. ì´ˆê¸° ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ (ë™ê¸° ì‹¤í–‰)
        def emergency_data_collection():
            logger.info("ðŸš¨ ê¸´ê¸‰ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            try:
                if notion_config.is_available():
                    symbols = notion_config.get_all_symbols()
                    for symbol in symbols:
                        success = market_analyzer.ensure_recent_data(symbol, hours_back=1)
                        if success:
                            logger.info(f"âœ… {symbol} ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                        else:
                            logger.warning(f"âŒ {symbol} ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                        time.sleep(1)  # ì‹¬ë³¼ ê°„ ê°„ê²©
                logger.info("âœ… ê¸´ê¸‰ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        emergency_thread = threading.Thread(target=emergency_data_collection, daemon=True)
        emergency_thread.start()
        
        # 8. ë°±ê·¸ë¼ìš´ë“œ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ (ë” ë§Žì€ ë°ì´í„°)
        def background_historical_collection():
            logger.info("ðŸ”„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            try:
                # ê¸´ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸°
                emergency_thread.join(timeout=60)
                
                if notion_config.is_available():
                    symbols = notion_config.get_all_symbols()
                    initialize_historical_data(symbols, days=3)  # 3ì¼ë¡œ ì¶•ì†Œ
                else:
                    initialize_historical_data(days=3)
                logger.info("âœ… ë°±ê·¸ë¼ìš´ë“œ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        historical_thread = threading.Thread(target=background_historical_collection, daemon=True)
        historical_thread.start()
        
        # # 9. ì‹œê°„ ë™ê¸°í™” ëŒ€ê¸° ë¡œì§ ì•„ì§ì€ ì£¼ì„ì²˜ë¦¬. docsë¥¼ ì´ìš©í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•¨.
        # current_time = datetime.now()
        # logger.info(f"ðŸ•’ í˜„ìž¬ ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # # ë‹¤ìŒ 5ë¶„ ë‹¨ìœ„ ì •ê°ê¹Œì§€ ëŒ€ê¸°
        # next_sync_minute = ((current_time.minute // 5) + 1) * 5
        # if next_sync_minute >= 60:
        #     next_sync_time = current_time.replace(hour=current_time.hour + 1, minute=0, second=0, microsecond=0)
        # else:
        #     next_sync_time = current_time.replace(minute=next_sync_minute, second=0, microsecond=0)
        
        # wait_seconds = (next_sync_time - current_time).total_seconds()
        
        # if wait_seconds > 0 and wait_seconds <= 300:  # ìµœëŒ€ 5ë¶„ë§Œ ëŒ€ê¸°
        #     logger.info(f"â³ ë‹¤ìŒ ë™ê¸°í™” ì§€ì ê¹Œì§€ ëŒ€ê¸°: {next_sync_time.strftime('%H:%M')} ({wait_seconds:.0f}ì´ˆ)")
            
        #     # ëŒ€ê¸° ì¤‘ì—ë„ ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        #     def show_startup_progress():
        #         for i in range(int(wait_seconds), 0, -10):
        #             if i <= 60:
        #                 logger.info(f"ðŸ•’ ë™ê¸°í™” ëŒ€ê¸° ì¤‘... {i}ì´ˆ ë‚¨ìŒ")
        #             time.sleep(min(10, i))
            
        #     progress_thread = threading.Thread(target=show_startup_progress, daemon=True)
        #     progress_thread.start()
            
        #     # ì‹¤ì œ ëŒ€ê¸°
        #     await asyncio.sleep(wait_seconds)
        #     logger.info(f"âœ… ë™ê¸°í™” ì§€ì  ë„ë‹¬: {datetime.now().strftime('%H:%M:%S')}")
        # else:
        #     logger.info("ë™ê¸°í™” ëŒ€ê¸° ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì´ë¯¸ ë™ê¸°í™”ë¨ - ì¦‰ì‹œ ì‹œìž‘")
        

        # 9. í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œìž‘
        monitor_success = position_monitor.start_monitoring()
        if monitor_success:
            logger.info("ðŸ” ì‹¤ì‹œê°„ í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìž‘")
        else:
            logger.warning("âš ï¸ í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìž‘ ì‹¤íŒ¨")

        # 10. ì‹œìŠ¤í…œ ìƒíƒœ ìµœì¢… ìš”ì•½
        logger.info("ðŸš€ === ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ===")
        logger.info(f"ðŸ“Š ê°œë³„ ë¶„ì„ ì—ì´ì „íŠ¸: {'âœ…' if ai_system.is_available() else 'âŒ'}")
        logger.info(f"ðŸ¤– ì´ê´„ ì—ì´ì „íŠ¸: {'âœ…' if master_agent.is_available() else 'âŒ'}")
        logger.info(f"ðŸ’¼ ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤: âœ…")
        logger.info(f"ðŸ“ˆ ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘: âœ…")
        logger.info(f"ðŸ“ ë…¸ì…˜ ì—°ë™: {'âœ…' if notion_logger.is_available() else 'âŒ'}")
        logger.info(f"âš™ï¸ ì—ì´ì „íŠ¸ ê´€ë¦¬: {'âœ…' if notion_config.is_available() else 'âŒ'}")
        logger.info(f"ðŸ•’ ì‹œê°„ ë™ê¸°í™”: âœ…")
        logger.info("ì›¹ì„œë²„ ì‹œìž‘ ì™„ë£Œ - ì‹œê°„ ë™ê¸°í™” ê¸°ë°˜ AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ í™œì„±í™”")
        
    except Exception as e:
        logger.error(f"âŒ ì‹œìž‘ ì‹œ ì˜¤ë¥˜: {e}")
        # ì¤‘ìš”í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë˜ë„ë¡ í•¨

@app.on_event("shutdown")
async def shutdown_event():
    """ì•± ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    logger.info("Trading Bot API ì¢…ë£Œ")
    stop_data_collection()
    signal_based_scheduler.stop_scheduler()
    position_monitor.stop_monitoring()


# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    """API ë£¨íŠ¸"""
    return {
        "message": "Trading Bot API v2.0 (Signal-Based)",
        "version": "2.0.0",
        "mode": "signal_based",
        "timeframes": TIMEFRAMES,
        "features": {
            "multi_timeframe_analysis": True,
            "ai_agents": ai_system.is_available(),
            "notion_logging": notion_logger.is_available(),
            "agent_management": notion_config.is_available(),
            "trading_engine": trading_engine.is_active(),
            "signal_based_scheduler": True,
            "available_agents": notion_config.get_agent_names() if notion_config.is_available() else []
        },
        "timestamp": datetime.now().isoformat()
    }


@app.get("/status")
async def get_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        current_price = db.get_current_price(DEFAULT_SYMBOL)
        
        # ê° ì‹œê°„ë´‰ë³„ ë°ì´í„° ìƒíƒœ í™•ì¸
        timeframe_status = {}
        for tf in TIMEFRAMES:
            candles = db.get_candles(DEFAULT_SYMBOL, tf, limit=1)
            timeframe_status[tf] = {
                "data_available": not candles.empty,
                "last_update": candles['timestamp'].iloc[-1].isoformat() if not candles.empty else None
            }
        
        current_time = datetime.now()
        
        return {
            "status": "running" if collection_status["running"] else "stopped",
            "mode": "synchronized_signal_based_with_master_agent",
            "system_time": current_time.isoformat(),
            "collection_status": collection_status,
            "scheduler_status": scheduler_status,
            "position_monitor_status": position_monitor.get_monitor_status(),  # ì´ ì¤„ ì¶”ê°€
            "sync_info": {
                "enabled": True,
                "current_minute": current_time.minute,
                "scheduler_running": signal_based_scheduler.running
            },
            "current_price": current_price,
            "timeframe_status": timeframe_status,
            "ai_available": ai_system.is_available(),
            "master_agent_available": master_agent.is_available(),
            "notion_available": notion_logger.is_available(),
            "agent_system_available": notion_config.is_available(),
            "trading_engine_status": trading_engine.get_status(),
            "portfolio_status": virtual_portfolio.get_portfolio_status(),
            "portfolio_statistics": db.get_portfolio_statistics(),
            "available_agents": notion_config.get_agent_names() if notion_config.is_available() else [],
            "timestamp": current_time.isoformat()
        }

    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/agents")
async def get_agents():
    """ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¸ë ˆì´ë”© ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        if not notion_config.is_available():
            raise HTTPException(status_code=503, detail="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        agents = notion_config.get_all_agents()
        agent_list = []
        
        for name, info in agents.items():
            agent_list.append({
                "name": name,
                "symbol": info['symbol'],
                "symbol_display": get_symbol_display_name(info['symbol']),
                "timeframes": info['timeframes'],
                "strategy_preview": info['strategy'][:100] + "..." if len(info['strategy']) > 100 else info['strategy'],
                "is_active": info['is_active']
            })
        
        return {
            "status": "running" if collection_status["running"] else "stopped",
            "mode": "signal_based_with_master_agent",
            "collection_status": collection_status,
            "scheduler_status": scheduler_status,
            "current_price": current_price,
            "timeframe_status": timeframe_status,
            "ai_available": ai_system.is_available(),
            "master_agent_available": master_agent.is_available(),
            "notion_available": notion_logger.is_available(),
            "agent_system_available": notion_config.is_available(),
            "trading_engine_status": trading_engine.get_status(),
            "portfolio_status": virtual_portfolio.get_portfolio_status(),
            "portfolio_statistics": db.get_portfolio_statistics(),
            "available_agents": notion_config.get_agent_names() if notion_config.is_available() else [],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/symbols")
async def get_symbols():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        # ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•˜ëŠ” ì‹¬ë³¼ë“¤
        agent_symbols = notion_config.get_all_symbols() if notion_config.is_available() else []
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥ëœ ì‹¬ë³¼ë“¤
        db_symbols = db.get_available_symbols()
        
        # ë°ì´í„° ìˆ˜ì§‘ê¸°ì˜ í™œì„± ì‹¬ë³¼ë“¤
        active_symbols = market_analyzer.get_active_symbols()
        
        symbol_info = []
        all_symbols = list(set(agent_symbols + db_symbols + active_symbols))
        
        for symbol in all_symbols:
            symbol_display = get_symbol_display_name(symbol)
            agents_using = [name for name, info in notion_config.get_all_agents().items() 
                          if info['symbol'] == symbol] if notion_config.is_available() else []
            
            symbol_info.append({
                "symbol": symbol,
                "symbol_display": symbol_display,
                "agents_using": agents_using,
                "agent_count": len(agents_using),
                "has_data": symbol in db_symbols,
                "collecting_data": symbol in active_symbols
            })
        
        return {
            "symbols": symbol_info,
            "total_count": len(symbol_info),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹¬ë³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/price/{symbol}")
async def get_symbol_price(symbol: str):
    """íŠ¹ì • ì‹¬ë³¼ì˜ í˜„ìž¬ ê°€ê²© ì¡°íšŒ"""
    try:
        normalized_symbol = normalize_symbol(symbol)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì‹  ê°€ê²©
        price_data = db.get_current_price(normalized_symbol)
        
        if not price_data:
            # ì‹¤ì‹œê°„ ì¡°íšŒ ì‹œë„
            market_data = market_analyzer.get_market_data(normalized_symbol)
            if market_data:
                return {
                    "symbol": normalized_symbol,
                    "symbol_display": get_symbol_display_name(normalized_symbol),
                    "price": market_data['price'],
                    "change_24h": market_data.get('change_24h'),
                    "volume_24h": market_data.get('volume_24h'),
                    "timestamp": market_data['timestamp']
                }
            else:
                raise HTTPException(status_code=404, detail=f"{symbol} ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return {
            "symbol": normalized_symbol,
            "symbol_display": get_symbol_display_name(normalized_symbol),
            "price": price_data['price'],
            "change_24h": price_data['change_24h'],
            "volume_24h": price_data['volume_24h'],
            "timestamp": price_data['timestamp']
        }
        
    except Exception as e:
        logger.error(f"{symbol} ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/agents/reload")
async def reload_agents():
    """ì—ì´ì „íŠ¸ ì„¤ì • ìƒˆë¡œê³ ì¹¨"""
    try:
        if not notion_config.is_available():
            raise HTTPException(status_code=503, detail="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        success = notion_config.reload_agents()
        
        if success:
            agents = notion_config.get_agent_names()
            # ìƒˆë¡œ ë¡œë“œëœ ì‹¬ë³¼ë“¤ë¡œ ë°ì´í„° ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸
            symbols = notion_config.get_all_symbols()
            market_analyzer.update_active_symbols(symbols)
            
            return {
                "success": True,
                "message": "ì—ì´ì „íŠ¸ ì„¤ì •ì´ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤",
                "loaded_agents": agents,
                "active_symbols": symbols,
                "count": len(agents),
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail="ì—ì´ì „íŠ¸ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"ì—ì´ì „íŠ¸ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/analyze/agent/{agent_name}")
async def analyze_with_agent(agent_name: str, analysis_periods: int = 50):
    """íŠ¹ì • ì—ì´ì „íŠ¸ë¡œ ì‹œìž¥ ë¶„ì„"""
    try:
        if not ai_system.is_available():
            raise HTTPException(status_code=503, detail="AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if not notion_config.is_available():
            raise HTTPException(status_code=503, detail="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì—ì´ì „íŠ¸ ì¡´ìž¬ í™•ì¸
        agent_info = notion_config.get_agent(agent_name)
        if not agent_info:
            available_agents = notion_config.get_agent_names()
            raise HTTPException(
                status_code=404, 
                detail=f"ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_name}. ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {available_agents}"
            )
        
        # AI ë¶„ì„ ìˆ˜í–‰
        logger.info(f"ðŸš€ APIë¥¼ í†µí•œ {agent_name} ë¶„ì„ ìš”ì²­ ì‹œìž‘")
        result = ai_system.analyze_with_agent(agent_name, analysis_periods)
        
        if not result:
            raise HTTPException(status_code=500, detail="AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        # í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ ì‹¬ë³¼ë¡œ í˜„ìž¬ê°€ ì¡°íšŒ
        agent_symbol = agent_info['symbol']
        current_price_data = db.get_current_price(agent_symbol)
        current_price = current_price_data['price'] if current_price_data else 0
        
        # ë…¸ì…˜ì— ì €ìž¥ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        notion_page_id = None
        if notion_logger.is_available():
            logger.info(f"ðŸ“ ë…¸ì…˜ íŽ˜ì´ì§€ ìƒì„± ì¤‘...")
            notion_page_id = notion_logger.create_analysis_page(result, current_price)
            if notion_page_id:
                logger.info(f"âœ… ë…¸ì…˜ íŽ˜ì´ì§€ ìƒì„± ì™„ë£Œ: {notion_page_id}")
            else:
                logger.warning("âŒ ë…¸ì…˜ íŽ˜ì´ì§€ ìƒì„± ì‹¤íŒ¨")
        
        return {
            "success": True,
            "agent_name": agent_name,
            "symbol": agent_symbol,
            "symbol_display": get_symbol_display_name(agent_symbol),
            "timeframes_used": result.get('timeframes_used', []),
            "analysis": result,
            "current_price": current_price,
            "notion_page_id": notion_page_id,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.get("/candles/{symbol}/{timeframe}")
async def get_symbol_candles(symbol: str, timeframe: str, limit: int = 100):
    """íŠ¹ì • ì‹¬ë³¼ì˜ ìº”ë“¤ ë°ì´í„° ì¡°íšŒ"""
    try:
        if timeframe not in TIMEFRAMES:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {timeframe}. ì§€ì›: {TIMEFRAMES}")
        
        if limit > 1000:
            limit = 1000
        
        normalized_symbol = normalize_symbol(symbol)
        symbol_display = get_symbol_display_name(normalized_symbol)
        
        logger.info(f"ðŸ“Š ìº”ë“¤ ë°ì´í„° ì¡°íšŒ: {normalized_symbol} {timeframe} (limit: {limit})")
        
        candles_df = db.get_candles(normalized_symbol, timeframe, limit)
        
        if candles_df.empty:
            logger.warning(f"âŒ {normalized_symbol} {timeframe} ìº”ë“¤ ë°ì´í„° ì—†ìŒ")
            return {
                "symbol": normalized_symbol,
                "symbol_display": symbol_display,
                "timeframe": timeframe,
                "data": [],
                "count": 0,
                "message": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                "timestamp": datetime.now().isoformat()
            }
        
        # íƒ€ìž„ìŠ¤íƒ¬í”„ë¥¼ ë¬¸ìžì—´ë¡œ ë³€í™˜
        candles_data = []
        for _, row in candles_df.iterrows():
            try:
                candle = {
                    "timestamp": row['timestamp'].isoformat() if hasattr(row['timestamp'], 'isoformat') else str(row['timestamp']),
                    "open": float(row['open']),
                    "high": float(row['high']),
                    "low": float(row['low']),
                    "close": float(row['close']),
                    "volume": float(row['volume'])
                }
                candles_data.append(candle)
            except Exception as e:
                logger.warning(f"ìº”ë“¤ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
                continue
        
        latest_time = candles_df['timestamp'].iloc[-1]
        latest_time_str = latest_time.strftime('%Y-%m-%d %H:%M:%S') if hasattr(latest_time, 'strftime') else str(latest_time)
        
        logger.info(f"âœ… {normalized_symbol} {timeframe} ìº”ë“¤ {len(candles_data)}ê°œ ë°˜í™˜ (ìµœì‹ : {latest_time_str})")
        
        return {
            "symbol": normalized_symbol,
            "symbol_display": symbol_display,
            "timeframe": timeframe,
            "data": candles_data,
            "count": len(candles_data),
            "latest_data_time": latest_time_str,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"{symbol} {timeframe} ìº”ë“¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ìº”ë“¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/indicators/{symbol}/{timeframe}")
async def get_symbol_technical_indicators(symbol: str, timeframe: str):
    """íŠ¹ì • ì‹¬ë³¼ì˜ ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ"""
    try:
        if timeframe not in TIMEFRAMES:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {timeframe}")
        
        normalized_symbol = normalize_symbol(symbol)
        symbol_display = get_symbol_display_name(normalized_symbol)
        
        signals = market_analyzer.get_technical_signals(normalized_symbol, timeframe, analysis_periods=50)
        
        if not signals:
            return {
                "symbol": normalized_symbol,
                "symbol_display": symbol_display,
                "timeframe": timeframe,
                "message": "ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "timestamp": datetime.now().isoformat()
            }
        
        return {
            "symbol": normalized_symbol,
            "symbol_display": symbol_display,
            "timeframe": timeframe,
            "analysis_periods": signals.get('analysis_periods', 50),
            "current_indicators": signals.get('current_indicators', {}),
            "indicators_timeseries": signals.get('indicators_timeseries', {}),
            "recent_candles": signals.get('recent_candles', []),
            "recent_volumes": signals.get('recent_volumes', []),
            "signals": signals.get('signals', {}),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"{symbol} {timeframe} ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/indicators/multi/{symbol}")
async def get_multi_timeframe_indicators_for_symbol(symbol: str, timeframes: str = "5m,15m,1h,4h", analysis_periods: int = 50):
    """íŠ¹ì • ì‹¬ë³¼ì˜ ë©€í‹° íƒ€ìž„í”„ë ˆìž„ ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ"""
    try:
        normalized_symbol = normalize_symbol(symbol)
        
        # ì‹œê°„ë´‰ íŒŒì‹±
        timeframe_list = [tf.strip() for tf in timeframes.split(",")]
        
        # ìœ íš¨í•œ ì‹œê°„ë´‰ì¸ì§€ í™•ì¸
        invalid_timeframes = [tf for tf in timeframe_list if tf not in TIMEFRAMES]
        if invalid_timeframes:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {invalid_timeframes}")
        
        # ë©€í‹° íƒ€ìž„í”„ë ˆìž„ ë°ì´í„° ìˆ˜ì§‘
        multi_data = market_analyzer.get_multi_timeframe_data(normalized_symbol, timeframe_list, analysis_periods)
        
        if not multi_data:
            raise HTTPException(status_code=404, detail=f"{symbol} ë©€í‹° íƒ€ìž„í”„ë ˆìž„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return {
            "symbol": normalized_symbol,
            "symbol_display": get_symbol_display_name(normalized_symbol),
            "multi_timeframe_data": multi_data,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"{symbol} ë©€í‹° íƒ€ìž„í”„ë ˆìž„ ì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/analysis/history")
async def get_analysis_history(limit: int = 10, symbol: str = None):
    """AI ë¶„ì„ ížˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        if limit > 50:
            limit = 50
        
        if symbol:
            normalized_symbol = normalize_symbol(symbol)
            history = db.get_ai_analysis_history(normalized_symbol, limit)
            
            return {
                "symbol": normalized_symbol,
                "symbol_display": get_symbol_display_name(normalized_symbol),
                "history": history,
                "count": len(history),
                "timestamp": datetime.now().isoformat()
            }
        else:
            history = ai_system.get_analysis_history(limit)
            
            return {
                "symbol": "ALL",
                "history": history,
                "count": len(history),
                "timestamp": datetime.now().isoformat()
            }
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ížˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/data/collect")
async def manual_data_collection(background_tasks: BackgroundTasks, symbols: str = None):
    """ìˆ˜ë™ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        # ì‹¬ë³¼ íŒŒì‹±
        if symbols:
            symbol_list = [s.strip() for s in symbols.split(",")]
        else:
            symbol_list = notion_config.get_all_symbols() if notion_config.is_available() else None
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
        background_tasks.add_task(initialize_historical_data, symbol_list, 5)
        
        return {
            "message": "ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œìž‘í–ˆìŠµë‹ˆë‹¤",
            "symbols": symbol_list or ["ê¸°ë³¸ ì‹¬ë³¼ë“¤"],
            "timeframes": TIMEFRAMES,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ì‹œê·¸ë„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/scheduler/status")
async def get_scheduler_status():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
    try:
        status = signal_based_scheduler.get_scheduler_status()
        return {
            "success": True,
            "scheduler_status": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/start")
async def start_scheduler():
    """ì‹œê·¸ë„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘"""
    try:
        success = signal_based_scheduler.start_scheduler()
        if success:
            return {
                "success": True,
                "message": "ì‹œê·¸ë„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤",
                "status": signal_based_scheduler.get_scheduler_status(),
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
                "status": signal_based_scheduler.get_scheduler_status(),
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/stop")
async def stop_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
    try:
        signal_based_scheduler.stop_scheduler()
        return {
            "success": True,
            "message": "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
            "status": signal_based_scheduler.get_scheduler_status(),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/analysis/run")
async def run_immediate_analysis():
    """ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ ë° ë¶„ì„ ì‹¤í–‰"""
    try:
        if not signal_based_scheduler.running:
            raise HTTPException(status_code=400, detail="ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤")
        
        result = signal_based_scheduler.run_immediate_signal_detection()
        
        if result:
            return {
                "success": True,
                "message": "ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ ë° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
                "timestamp": datetime.now().isoformat()
            }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¦‰ì‹œ ì‹œê·¸ë„ ê°ì§€ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/verification/run")
async def run_immediate_verification():
    """ì¦‰ì‹œ ê²€ì¦ ì‹¤í–‰"""
    try:
        if not signal_based_scheduler.running:
            raise HTTPException(status_code=400, detail="ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤")
        
        result = signal_based_scheduler.run_immediate_verification()
        
        if result:
            return {
                "success": True,
                "message": "ì¦‰ì‹œ ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "result": result,
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "ì¦‰ì‹œ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
                "timestamp": datetime.now().isoformat()
            }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¦‰ì‹œ ê²€ì¦ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ì‹œê·¸ë„ ê°ì§€ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/signals/{symbol}")
async def get_symbol_signals(symbol: str, timeframe: str = "5m"):
    """íŠ¹ì • ì‹¬ë³¼ì˜ í˜„ìž¬ ì‹œê·¸ë„ ì¡°íšŒ"""
    try:
        if timeframe not in TIMEFRAMES:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {timeframe}")
        
        normalized_symbol = normalize_symbol(symbol)
        
        # ì‹œê·¸ë„ ê°ì§€ê¸° ì´ˆê¸°í™”
        from market_analyzer import SignalDetector
        signal_detector = SignalDetector()
        
        # ì‹œê·¸ë„ ê°ì§€
        signals = signal_detector.detect_signals_for_symbol(normalized_symbol, timeframe)
        
        return {
            "symbol": normalized_symbol,
            "symbol_display": get_symbol_display_name(normalized_symbol),
            "timeframe": timeframe,
            "signals": signals,
            "signal_count": len(signals),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"{symbol} ì‹œê·¸ë„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/signals/all")
async def get_all_signals(timeframe: str = "5m"):
    """ëª¨ë“  í™œì„± ì‹¬ë³¼ì˜ ì‹œê·¸ë„ ì¡°íšŒ"""
    try:
        if timeframe not in TIMEFRAMES:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„ë´‰: {timeframe}")
        
        if not notion_config.is_available():
            raise HTTPException(status_code=503, detail="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        active_symbols = notion_config.get_all_symbols()
        
        # ì‹œê·¸ë„ ê°ì§€ê¸° ì´ˆê¸°í™”
        from market_analyzer import SignalDetector
        signal_detector = SignalDetector()
        
        # ëª¨ë“  ì‹¬ë³¼ì˜ ì‹œê·¸ë„ ê°ì§€
        all_signals = signal_detector.detect_signals_for_all_symbols(active_symbols, timeframe)
        
        # ì‹œê·¸ë„ ìš”ì•½
        signal_summary = signal_detector.get_signal_summary(all_signals)
        
        return {
            "timeframe": timeframe,
            "active_symbols": active_symbols,
            "signals_by_symbol": all_signals,
            "summary": signal_summary,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì „ì²´ ì‹œê·¸ë„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={"error": "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "timestamp": datetime.now().isoformat()}
    )


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜", "timestamp": datetime.now().isoformat()}
    )

@app.get("/portfolio/status")
async def get_portfolio_status():
    """ê°€ìƒ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ ì¡°íšŒ"""
    try:
        status = virtual_portfolio.get_portfolio_status()
        return {
            "success": True,
            "portfolio": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/portfolio/statistics")
async def get_portfolio_statistics():
    """í¬íŠ¸í´ë¦¬ì˜¤ í†µê³„ ì¡°íšŒ"""
    try:
        stats = db.get_portfolio_statistics()
        return {
            "success": True,
            "statistics": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/trades/history")
async def get_trades_history(limit: int = 20):
    """ê°€ìƒ ê±°ëž˜ ížˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        if limit > 100:
            limit = 100
        
        trades = db.get_virtual_trades_history(limit)
        return {
            "success": True,
            "trades": trades,
            "count": len(trades),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ê±°ëž˜ ížˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/decisions/history")
async def get_master_decisions_history(limit: int = 20):
    """ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ížˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        if limit > 100:
            limit = 100
        
        decisions = db.get_master_decisions_history(limit)
        return {
            "success": True,
            "decisions": decisions,
            "count": len(decisions),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì´ê´„ ê²°ì • ížˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/market/sentiment/{symbol}")
async def get_market_sentiment(symbol: str):
    """ì‹œìž¥ ì„¼í‹°ë¨¼íŠ¸ ì¡°íšŒ"""
    try:
        normalized_symbol = normalize_symbol(symbol)
        sentiment = market_data_collector.get_market_sentiment(normalized_symbol)
        
        return {
            "success": True,
            "symbol": normalized_symbol,
            "symbol_display": get_symbol_display_name(normalized_symbol),
            "sentiment": sentiment,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"{symbol} ì‹œìž¥ ì„¼í‹°ë¨¼íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/portfolio/reset")
async def reset_portfolio():
    """í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™” (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        # ê¸°ì¡´ í¬ì§€ì…˜ ê°•ì œ ì²­ì‚°
        if virtual_portfolio.current_position:
            current_price_data = db.get_current_price(virtual_portfolio.current_position['symbol'])
            current_price = current_price_data['price'] if current_price_data else virtual_portfolio.current_position['entry_price']
            virtual_portfolio.exit_position(current_price, "Portfolio Reset")
        
        # ìž”ê³  ì´ˆê¸°í™”
        virtual_portfolio.current_balance = virtual_portfolio.initial_balance
        virtual_portfolio.current_position = None
        
        logger.info("í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        return {
            "success": True,
            "message": "í¬íŠ¸í´ë¦¬ì˜¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤",
            "portfolio": virtual_portfolio.get_portfolio_status(),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/master/decision/{symbol}")
async def manual_master_decision(symbol: str):
    """ìˆ˜ë™ ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ì‹¤í–‰"""
    try:
        if not master_agent.is_available():
            raise HTTPException(status_code=503, detail="ì´ê´„ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        normalized_symbol = normalize_symbol(symbol)
        
        # ìµœê·¼ AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        recent_analysis = db.get_ai_analysis_history(normalized_symbol, 1)
        if not recent_analysis:
            raise HTTPException(status_code=404, detail=f"{symbol}ì˜ ìµœê·¼ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì ì ˆí•œ í˜•íƒœë¡œ ë³€í™˜
        analysis_data = recent_analysis[0]
        individual_analysis = {
            'symbol': normalized_symbol,
            'recommendation': analysis_data['recommendation'],
            'confidence': analysis_data['confidence'],
            'target_price': analysis_data.get('target_price'),
            'stop_loss': analysis_data.get('stop_loss'),
            'analysis': analysis_data['analysis'],
            'reasons': []  # ê¸°ë³¸ê°’
        }
        
        # ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ì‹¤í–‰
        master_decision = master_agent.make_trading_decision(individual_analysis)
        
        if not master_decision:
            raise HTTPException(status_code=500, detail="ì´ê´„ ì—ì´ì „íŠ¸ ê²°ì • ì‹¤íŒ¨")
        
        # ë…¸ì…˜ íŽ˜ì´ì§€ ìƒì„±
        trading_page_id = None
        if notion_logger.is_available():
            trading_page_id = notion_logger.create_trading_decision_page(
                master_decision, 
                individual_analysis
            )
        
        return {
            "success": True,
            "symbol": normalized_symbol,
            "symbol_display": get_symbol_display_name(normalized_symbol),
            "master_decision": master_decision,
            "trading_page_id": trading_page_id,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ì´ê´„ ê²°ì • ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/scheduler/sync-info")
async def get_scheduler_sync_info():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œê°„ ë™ê¸°í™” ì •ë³´ ì¡°íšŒ"""
    try:
        current_time = datetime.now()
        
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë“¤ ê³„ì‚°
        def get_next_minutes(minute_list):
            current_minute = current_time.minute
            next_minute = None
            for minute in sorted(minute_list):
                if minute > current_minute:
                    next_minute = minute
                    break
            if next_minute is None:
                next_minute = min(minute_list)
                return current_time.replace(hour=current_time.hour + 1, minute=next_minute, second=0, microsecond=0)
            else:
                return current_time.replace(minute=next_minute, second=0, microsecond=0)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        data_schedule = {
            '5m': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56],
            '15m': [1, 16, 31, 46],
            '1h': [1]
        }
        signal_schedule = [3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58]
        verification_schedule = [3, 18, 33, 48]
        
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë“¤
        next_times = {
            'data_collection': {
                '5m': get_next_minutes(data_schedule['5m']).isoformat(),
                '15m': get_next_minutes(data_schedule['15m']).isoformat(),
                '1h': get_next_minutes(data_schedule['1h']).isoformat()
            },
            'signal_check': get_next_minutes(signal_schedule).isoformat(),
            'verification': get_next_minutes(verification_schedule).isoformat()
        }
        
        return {
            "success": True,
            "current_time": current_time.isoformat(),
            "schedule_config": {
                "data_collection": data_schedule,
                "signal_check": signal_schedule,
                "verification": verification_schedule
            },
            "next_execution_times": next_times,
            "scheduler_running": signal_based_scheduler.running,
            "sync_mode": "enabled",
            "timestamp": current_time.isoformat()
        }
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ë™ê¸°í™” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/data/sync-collect")
async def sync_data_collection():
    """ì‹œê°„ ë™ê¸°í™” ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ ìˆ˜ë™ ì‹¤í–‰"""
    try:
        if not notion_config.is_available():
            raise HTTPException(status_code=503, detail="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        active_symbols = notion_config.get_all_symbols()
        if not active_symbols:
            raise HTTPException(status_code=400, detail="í™œì„±í™”ëœ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        logger.info(f"ðŸ”„ ìˆ˜ë™ ë™ê¸°í™” ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘: {active_symbols}")
        
        results = {}
        success_count = 0
        
        for symbol in active_symbols:
            try:
                # ìµœì‹  2ì‹œê°„ ë°ì´í„° í™•ë³´
                success = market_analyzer.ensure_recent_data(symbol, hours_back=2)
                results[symbol] = {
                    "success": success,
                    "message": "ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ" if success else "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"
                }
                if success:
                    success_count += 1
                
                time.sleep(0.5)  # ì‹¬ë³¼ ê°„ ê°„ê²©
                
            except Exception as e:
                results[symbol] = {
                    "success": False,
                    "error": str(e)
                }
        
        return {
            "success": True,
            "message": f"ë™ê¸°í™” ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(active_symbols)} ì„±ê³µ",
            "symbols": active_symbols,
            "results": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë™ê¸°í™” ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/system/time-status")
async def get_system_time_status():
    """ì‹œìŠ¤í…œ ì‹œê°„ ìƒíƒœ ë° ë™ê¸°í™” ì •ë³´"""
    try:
        current_time = datetime.now()
        
        # í˜„ìž¬ ë¶„ì´ ì–´ë–¤ ìŠ¤ì¼€ì¤„ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸
        current_minute = current_time.minute
        
        # ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„ì¸ì§€ í™•ì¸
        is_data_5m = current_minute in [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56]
        is_data_15m = current_minute in [1, 16, 31, 46]
        is_data_1h = current_minute in [1]
        
        # ì‹œê·¸ë„ ì²´í¬ ì‹œê°„ì¸ì§€ í™•ì¸
        is_signal_check = current_minute in [3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58]
        
        # ê²€ì¦ ì‹œê°„ì¸ì§€ í™•ì¸
        is_verification = current_minute in [3, 18, 33, 48]
        
        # ë‹¤ìŒ ì •ê° 5ë¶„ê¹Œì§€ì˜ ì‹œê°„
        next_5min = ((current_minute // 5) + 1) * 5
        if next_5min >= 60:
            next_5min_time = current_time.replace(hour=current_time.hour + 1, minute=0, second=0, microsecond=0)
        else:
            next_5min_time = current_time.replace(minute=next_5min, second=0, microsecond=0)
        
        time_to_next_5min = (next_5min_time - current_time).total_seconds()
        
        return {
            "success": True,
            "system_time": current_time.isoformat(),
            "current_minute": current_minute,
            "current_second": current_time.second,
            "active_schedules": {
                "data_collection_5m": is_data_5m,
                "data_collection_15m": is_data_15m,
                "data_collection_1h": is_data_1h,
                "signal_check": is_signal_check,
                "verification": is_verification
            },
            "next_5min_mark": next_5min_time.isoformat(),
            "seconds_to_next_5min": int(time_to_next_5min),
            "scheduler_status": {
                "running": signal_based_scheduler.running,
                "mode": "synchronized" if signal_based_scheduler.running else "stopped"
            },
            "timestamp": current_time.isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì‹œê°„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/scheduler/force-sync")
async def force_scheduler_sync():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ê°•ì œ ë™ê¸°í™”"""
    try:
        if not signal_based_scheduler.running:
            raise HTTPException(status_code=400, detail="ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤")
        
        logger.info("ðŸ•’ ìŠ¤ì¼€ì¤„ëŸ¬ ê°•ì œ ë™ê¸°í™” ìš”ì²­")
        
        # í˜„ìž¬ ì‹œê°„ ì •ë³´
        current_time = datetime.now()
        
        # ë‹¤ìŒ ë™ê¸°í™” ì§€ì ê¹Œì§€ì˜ ì‹œê°„ ê³„ì‚°
        signal_based_scheduler.wait_for_next_sync_point()
        
        # ë™ê¸°í™” í›„ ì‹œê°„
        sync_time = datetime.now()
        
        return {
            "success": True,
            "message": "ìŠ¤ì¼€ì¤„ëŸ¬ ê°•ì œ ë™ê¸°í™” ì™„ë£Œ",
            "before_sync": current_time.isoformat(),
            "after_sync": sync_time.isoformat(),
            "timestamp": sync_time.isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ê°•ì œ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    
# í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/position/monitor/status")
async def get_position_monitor_status():
    """í¬ì§€ì…˜ ëª¨ë‹ˆí„° ìƒíƒœ ì¡°íšŒ"""
    try:
        status = position_monitor.get_monitor_status()
        return {
            "success": True,
            "monitor_status": status,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ëª¨ë‹ˆí„° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/position/monitor/start")
async def start_position_monitor():
    """í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìž‘"""
    try:
        success = position_monitor.start_monitoring()
        return {
            "success": success,
            "message": "í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ì´ ì‹œìž‘ë˜ì—ˆìŠµë‹ˆë‹¤" if success else "í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìž‘ ì‹¤íŒ¨",
            "status": position_monitor.get_monitor_status(),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìž‘ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/position/monitor/stop")
async def stop_position_monitor():
    """í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    try:
        position_monitor.stop_monitoring()
        return {
            "success": True,
            "message": "í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
            "status": position_monitor.get_monitor_status(),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/position/check")
async def force_position_check():
    """ê°•ì œ í¬ì§€ì…˜ ì²´í¬ (í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        result = position_monitor.force_position_check()
        return {
            "success": True,
            "check_result": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ê°•ì œ í¬ì§€ì…˜ ì²´í¬ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/position/summary")
async def get_position_summary():
    """í˜„ìž¬ í¬ì§€ì…˜ ìš”ì•½ ì¡°íšŒ"""
    try:
        summary = virtual_portfolio.get_position_summary()
        return {
            "success": True,
            "position_summary": summary,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/position/exit")
async def manual_position_exit(reason: str = "Manual Exit"):
    """ìˆ˜ë™ í¬ì§€ì…˜ ì²­ì‚°"""
    try:
        if not virtual_portfolio.current_position:
            raise HTTPException(status_code=400, detail="ì²­ì‚°í•  í¬ì§€ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
        
        symbol = virtual_portfolio.current_position['symbol']
        current_price_data = db.get_current_price(symbol)
        
        if not current_price_data:
            raise HTTPException(status_code=404, detail=f"{symbol} í˜„ìž¬ê°€ ì¡°íšŒ ì‹¤íŒ¨")
        
        current_price = current_price_data['price']
        exit_info = virtual_portfolio.exit_position(current_price, reason)
        
        if exit_info:
            return {
                "success": True,
                "message": "í¬ì§€ì…˜ì´ ìˆ˜ë™ìœ¼ë¡œ ì²­ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤",
                "exit_info": exit_info,
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail="í¬ì§€ì…˜ ì²­ì‚° ì‹¤íŒ¨")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ë™ í¬ì§€ì…˜ ì²­ì‚° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/position/flip/{symbol}")
async def manual_position_flip(symbol: str, direction: str, leverage: float = 2.0):
    """ìˆ˜ë™ í¬ì§€ì…˜ í”Œë¦½"""
    try:
        if direction not in ['LONG', 'SHORT']:
            raise HTTPException(status_code=400, detail="directionì€ LONG ë˜ëŠ” SHORTì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        normalized_symbol = normalize_symbol(symbol)
        current_price_data = db.get_current_price(normalized_symbol)
        
        if not current_price_data:
            raise HTTPException(status_code=404, detail=f"{symbol} í˜„ìž¬ê°€ ì¡°íšŒ ì‹¤íŒ¨")
        
        current_price = current_price_data['price']
        
        # í¬ì§€ì…˜ í”Œë¦½ ì‹¤í–‰
        success = virtual_portfolio.enter_position(
            normalized_symbol, direction, current_price, leverage, force_flip=True
        )
        
        if success:
            return {
                "success": True,
                "message": f"í¬ì§€ì…˜ í”Œë¦½ ì™„ë£Œ: {direction} {leverage}x",
                "symbol": normalized_symbol,
                "symbol_display": get_symbol_display_name(normalized_symbol),
                "new_position": virtual_portfolio.get_position_summary(),
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail="í¬ì§€ì…˜ í”Œë¦½ ì‹¤íŒ¨")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ë™ í¬ì§€ì…˜ í”Œë¦½ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/position/performance")
async def get_position_performance():
    """í¬ì§€ì…˜ ì„±ê³¼ ë¶„ì„"""
    try:
        portfolio_status = virtual_portfolio.get_portfolio_status()
        trading_stats = db.get_portfolio_statistics()
        
        # ìµœê·¼ ê±°ëž˜ ížˆìŠ¤í† ë¦¬
        recent_trades = db.get_virtual_trades_history(10)
        
        # ìˆ˜ìµë¥  ë¶„ì„
        if recent_trades:
            profitable_trades = [t for t in recent_trades if t.get('realized_pnl', 0) > 0]
            losing_trades = [t for t in recent_trades if t.get('realized_pnl', 0) < 0]
            
            avg_win = sum(t.get('realized_pnl', 0) for t in profitable_trades) / len(profitable_trades) if profitable_trades else 0
            avg_loss = sum(t.get('realized_pnl', 0) for t in losing_trades) / len(losing_trades) if losing_trades else 0
            
            profit_factor = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')
        else:
            avg_win = avg_loss = profit_factor = 0
        
        performance_data = {
            "portfolio_status": portfolio_status,
            "trading_statistics": trading_stats,
            "recent_trades_count": len(recent_trades),
            "performance_metrics": {
                "average_win": avg_win,
                "average_loss": avg_loss,
                "profit_factor": profit_factor,
                "total_return_percentage": portfolio_status.get('total_return', 0),
                "current_drawdown": max(0, portfolio_status.get('initial_balance', 0) - portfolio_status.get('total_value', 0))
            },
            "recent_trades": recent_trades[:5]  # ìµœê·¼ 5ê°œë§Œ
        }
        
        return {
            "success": True,
            "performance": performance_data,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ì„±ê³¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )